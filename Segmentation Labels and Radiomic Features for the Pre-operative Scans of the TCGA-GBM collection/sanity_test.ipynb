{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directory=\"D:/MLDatasets/TCGA-GBM Datasets/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "flair_files = sorted(glob(os.path.join(training_directory, f\"images_{0}\", \"*.nii.gz\")))\n",
    "t1_files = sorted(glob(os.path.join(training_directory, f\"images_{1}\", \"*.nii.gz\")))\n",
    "t1Gd_files = sorted(glob(os.path.join(training_directory, f\"images_{2}\", \"*.nii.gz\")))\n",
    "t2_files = sorted(glob(os.path.join(training_directory, f\"images_{3}\", \"*.nii.gz\")))\n",
    "mask_files = sorted(glob(os.path.join(training_directory, f\"segmentation\", \"*.nii.gz\")))\n",
    "print(len(flair_files))\n",
    "print(len(t1_files))\n",
    "print(len(t1Gd_files))\n",
    "print(len(t2_files))\n",
    "print(len(mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc8eaf8b4ac4688b6a0cfac0b2cae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Image shape: (240, 240, 155, 4)\n",
      "Mask shape: (240, 240, 155)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Resize,\n",
    "    Compose\n",
    ")\n",
    "\n",
    "current_using = False\n",
    "spatial_size=[128, 128, 144]\n",
    "smaller_transform = Compose(\n",
    "    Resize([128, 128, 144])\n",
    ")\n",
    "\n",
    "for i in tqdm(range(len(flair_files))):\n",
    "    flair_image = nib.load(flair_files[i]).get_fdata()\n",
    "    t1_image = nib.load(t1_files[i]).get_fdata()\n",
    "    t1Gd_image = nib.load(t1Gd_files[i]).get_fdata()\n",
    "    t2_image = nib.load(t2_files[i]).get_fdata()\n",
    "    combined_image = np.stack([flair_image, t1_image, t1Gd_image, t2_image], axis=3)\n",
    "\n",
    "    mask = nib.load(mask_files[i]).get_fdata()\n",
    "    mask = mask.astype(np.uint8)\n",
    "\n",
    "    flair_image = smaller_transform(flair_image)\n",
    "    t1_image = smaller_transform(t1_image)\n",
    "    t1Gd_image = smaller_transform(t1Gd_image)\n",
    "    t2_image = smaller_transform(t2_image)\n",
    "    \n",
    "    if(i == 0):\n",
    "        print(f\"Combined Image shape: {combined_image.shape}\")\n",
    "        print(f\"Mask shape: {mask.shape}\")\n",
    "    \n",
    "    combined_image = nib.Nifti1Image(combined_image, affine=np.eye(4))\n",
    "    mask = nib.Nifti1Image(mask, affine=np.eye(4))\n",
    "\n",
    "    if current_using == True:\n",
    "        nib.save(combined_image, os.path.join(training_directory, \"imagesv5\", f\"image_{i}.nii.gz\"))\n",
    "        nib.save(mask, os.path.join(training_directory, \"segmentationv5\", f\"mask_{i}.nii.gz\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorchMain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea52dcf60439bbfeb15ff1bd40b703081e3cad41733c2dee57afaa83da4e6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
