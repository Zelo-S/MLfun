{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm \n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directory=\"D:/MLDatasets/TCGA-GBM Datasets/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "102\n",
      "102\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "flair_files = sorted(glob(os.path.join(training_directory, f\"images_{0}\", \"*.nii.gz\")))\n",
    "t1Gd_files = sorted(glob(os.path.join(training_directory, f\"images_{1}\", \"*.nii.gz\")))\n",
    "t2_files = sorted(glob(os.path.join(training_directory, f\"images_{2}\", \"*.nii.gz\")))\n",
    "mask_files = sorted(glob(os.path.join(training_directory, f\"segmentation\", \"*.nii.gz\")))\n",
    "print(len(flair_files))\n",
    "print(len(t1Gd_files))\n",
    "print(len(t2_files))\n",
    "print(len(mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(flair_files)):\n",
    "    flair_image = nib.load(flair_files[i]).get_fdata()\n",
    "    t1Gd_image = nib.load(t1Gd_files[i]).get_fdata()\n",
    "    t2_image = nib.load(t2_files[i]).get_fdata()\n",
    "    mask = nib.load(mask_files[i]).get_fdata()\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask[mask==4] = 3\n",
    "\n",
    "    combined_image = np.stack([flair_image, t1Gd_image, t2_image], axis=3)\n",
    "    \n",
    "    np.save(os.path.join(training_directory, \"imagesv1\", f\"image_{i}.npy\"), combined_image)\n",
    "    np.save(os.path.join(training_directory, \"segmentationv1\", f\"mask_{i}.npy\"), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "def prepare(in_dir, pixdim=(1.0, 1.0, 1.0), a_min=0, a_max=503, spatial_size=[128,128,144], trainloader_batchsize=1):\n",
    "    print(\"Preparing...\")\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"imagesv1\", \"*.npy\")))\n",
    "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"segmentationv1\", \"*.npy\")))\n",
    "\n",
    "    '''DEBUG'''\n",
    "    print(f\"Length of path_train_volumes: {len(path_train_volumes)}\")    \n",
    "    print(f\"Length of path_train_segmentation: {len(path_train_segmentation)}\")    \n",
    "    '''DEBUG'''\n",
    "\n",
    "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "    \n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n",
    "    print(\"attempted cache\")\n",
    "    train_loader = DataLoader(train_ds, batch_size=trainloader_batchsize)\n",
    "    print(\"Preparing done.\")\n",
    "\n",
    "    return train_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing...\n",
      "Length of path_train_volumes: 102\n",
      "Length of path_train_segmentation: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/102 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.spatial.dictionary.Spacingd object at 0x0000024A24298D30>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:89\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[39mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data]\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items)\n\u001b[0;32m     90\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:53\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m transform(\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m---> 53\u001b[0m \u001b[39mreturn\u001b[39;00m transform(parameters)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\spatial\\dictionary.py:530\u001b[0m, in \u001b[0;36mSpacingd.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    527\u001b[0m original_spatial_shape \u001b[39m=\u001b[39m d[key]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    528\u001b[0m d[key], old_affine, new_affine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspacing_transform(\n\u001b[0;32m    529\u001b[0m     data_array\u001b[39m=\u001b[39md[key],\n\u001b[1;32m--> 530\u001b[0m     affine\u001b[39m=\u001b[39mmeta_data[\u001b[39m\"\u001b[39;49m\u001b[39maffine\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    531\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    532\u001b[0m     padding_mode\u001b[39m=\u001b[39mpadding_mode,\n\u001b[0;32m    533\u001b[0m     align_corners\u001b[39m=\u001b[39malign_corners,\n\u001b[0;32m    534\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    535\u001b[0m )\n\u001b[0;32m    536\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_transform(\n\u001b[0;32m    537\u001b[0m     d,\n\u001b[0;32m    538\u001b[0m     key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m     orig_size\u001b[39m=\u001b[39moriginal_spatial_shape,\n\u001b[0;32m    547\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'affine'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steve\\OneDrive\\Documents\\IntroToDL\\MLfun\\Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\\alittletesting.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainloader \u001b[39m=\u001b[39m prepare(training_directory)\n",
      "\u001b[1;32mc:\\Users\\steve\\OneDrive\\Documents\\IntroToDL\\MLfun\\Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\\alittletesting.ipynb Cell 6\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(in_dir, pixdim, a_min, a_max, spatial_size, trainloader_batchsize)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m train_files \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mvol\u001b[39m\u001b[39m\"\u001b[39m: image_name, \u001b[39m\"\u001b[39m\u001b[39mseg\u001b[39m\u001b[39m\"\u001b[39m: label_name} \u001b[39mfor\u001b[39;00m image_name, label_name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(path_train_volumes, path_train_segmentation)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m train_transforms \u001b[39m=\u001b[39m Compose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         LoadImaged(keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mvol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseg\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m train_ds \u001b[39m=\u001b[39m CacheDataset(data\u001b[39m=\u001b[39;49mtrain_files, transform\u001b[39m=\u001b[39;49mtrain_transforms,cache_rate\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mattempted cache\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_ds, batch_size\u001b[39m=\u001b[39mtrainloader_batchsize)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:723\u001b[0m, in \u001b[0;36mCacheDataset.__init__\u001b[1;34m(self, data, transform, cache_num, cache_rate, num_workers, progress, copy_cache, as_contiguous, hash_as_key, hash_func)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache: Union[List, Dict] \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 723\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_data(data)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:748\u001b[0m, in \u001b[0;36mCacheDataset.set_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n\u001b[1;32m--> 748\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m _compute_cache()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:737\u001b[0m, in \u001b[0;36mCacheDataset.set_data.<locals>._compute_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute_cache\u001b[39m():\n\u001b[0;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_num), \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_rate), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata))\n\u001b[1;32m--> 737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fill_cache()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:757\u001b[0m, in \u001b[0;36mCacheDataset._fill_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m    756\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress \u001b[39mand\u001b[39;00m has_tqdm:\n\u001b[1;32m--> 757\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    758\u001b[0m             tqdm(\n\u001b[0;32m    759\u001b[0m                 p\u001b[39m.\u001b[39;49mimap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_cache_item, \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_num)),\n\u001b[0;32m    760\u001b[0m                 total\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_num,\n\u001b[0;32m    761\u001b[0m                 desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLoading dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    762\u001b[0m             )\n\u001b[0;32m    763\u001b[0m         )\n\u001b[0;32m    764\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(p\u001b[39m.\u001b[39mimap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_cache_item, \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num)))\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\multiprocessing\\pool.py:868\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 868\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[39m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m, func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m wrap_exception \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:777\u001b[0m, in \u001b[0;36mCacheDataset._load_cache_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    776\u001b[0m     _xform \u001b[39m=\u001b[39m deepcopy(_transform) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[39melse\u001b[39;00m _transform\n\u001b[1;32m--> 777\u001b[0m     item \u001b[39m=\u001b[39m apply_transform(_xform, item)\n\u001b[0;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_contiguous:\n\u001b[0;32m    779\u001b[0m     item \u001b[39m=\u001b[39m convert_to_contiguous(item, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcontiguous_format)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:113\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         _log_stats(data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m--> 113\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplying transform \u001b[39m\u001b[39m{\u001b[39;00mtransform\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <monai.transforms.spatial.dictionary.Spacingd object at 0x0000024A24298D30>"
     ]
    }
   ],
   "source": [
    "\n",
    "trainloader = prepare(training_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorchMain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea52dcf60439bbfeb15ff1bd40b703081e3cad41733c2dee57afaa83da4e6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
