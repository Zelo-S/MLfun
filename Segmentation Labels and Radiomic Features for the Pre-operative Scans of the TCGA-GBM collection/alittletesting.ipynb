{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm \n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directory=\"D:/MLDatasets/TCGA-GBM Datasets/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "flair_files = sorted(glob(os.path.join(training_directory, f\"images_{0}\", \"*.nii.gz\")))\n",
    "t1_files = sorted(glob(os.path.join(training_directory, f\"images_{1}\", \"*.nii.gz\")))\n",
    "t1Gd_files = sorted(glob(os.path.join(training_directory, f\"images_{2}\", \"*.nii.gz\")))\n",
    "t2_files = sorted(glob(os.path.join(training_directory, f\"images_{3}\", \"*.nii.gz\")))\n",
    "mask_files = sorted(glob(os.path.join(training_directory, f\"segmentation\", \"*.nii.gz\")))\n",
    "print(len(flair_files))\n",
    "print(len(t1_files))\n",
    "print(len(t1Gd_files))\n",
    "print(len(t2_files))\n",
    "print(len(mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [04:15<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "current_using = True \n",
    "\n",
    "for i in tqdm(range(len(flair_files))):\n",
    "    flair_image = nib.load(flair_files[i]).get_fdata()\n",
    "    t1_image = nib.load(t1_files[i]).get_fdata()\n",
    "    t1Gd_image = nib.load(t1Gd_files[i]).get_fdata()\n",
    "    t2_image = nib.load(t2_files[i]).get_fdata()\n",
    "    combined_image = np.stack([flair_image, t1_image, t1Gd_image, t2_image], axis=3)\n",
    "\n",
    "    mask = nib.load(mask_files[i]).get_fdata()\n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    if(i == 0):\n",
    "        print(combined_image.shape)\n",
    "    \n",
    "    combined_image = nib.Nifti1Image(combined_image, affine=np.eye(4))\n",
    "    mask = nib.Nifti1Image(mask, affine=np.eye(4))\n",
    "\n",
    "    if current_using == True:\n",
    "        nib.save(combined_image, os.path.join(training_directory, \"imagesv4\", f\"image_{i}.nii.gz\"))\n",
    "        nib.save(mask, os.path.join(training_directory, \"segmentationv4\", f\"mask_{i}.nii.gz\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    Activationsd,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    EnsureChannelFirstd,\n",
    "    ToTensord\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "import torch\n",
    "\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            \n",
    "            label1 = torch.from_numpy(d[key] == 1)\n",
    "            label2 = torch.from_numpy(d[key] == 2)\n",
    "            label4 = torch.from_numpy(d[key] == 4) \n",
    "\n",
    "            result.append( # WT\n",
    "                torch.logical_or(torch.logical_or(label1, label2), label4)\n",
    "            )\n",
    "            \n",
    "            result.append( #TC\n",
    "                torch.logical_or(label1, label4)\n",
    "            )\n",
    "            \n",
    "            result.append( #EC\n",
    "                label4\n",
    "            )\n",
    "\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n",
    "\n",
    "def prepare(in_dir, pixdim=(1.0, 1.0, 1.0), a_min=0, a_max=503, spatial_size=[128,128,144, 3], trainloader_batchsize=1):\n",
    "    print(\"Preparing...\")\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"imagesv3\", \"*.nii.gz\")))\n",
    "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"segmentationv3\", \"*.nii.gz\")))\n",
    "\n",
    "    '''DEBUG'''\n",
    "    print(f\"Length of path_train_volumes: {len(path_train_volumes)}\")    \n",
    "    print(f\"Length of path_train_segmentation: {len(path_train_segmentation)}\")    \n",
    "    '''DEBUG'''\n",
    "    \n",
    "    train_files = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "    \n",
    "    train_transform = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            AddChanneld(keys=[\"image\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=\"image\"),\n",
    "            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            CropForegroundd(keys=['image', 'label'], source_key='image'),\n",
    "            Resized(keys=[\"image\", \"label\"], spatial_size=spatial_size, mode='nearest'),   \n",
    "            RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=spatial_size, random_size=False),\n",
    "            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transform,cache_rate=1.0)\n",
    "    train_loader = DataLoader(train_ds, batch_size=trainloader_batchsize)\n",
    "    print(\"Preparing done.\")\n",
    "\n",
    "    return train_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing...\n",
      "Length of path_train_volumes: 102\n",
      "Length of path_train_segmentation: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   0%|          | 0/102 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.spatial.dictionary.Orientationd object at 0x00000238816729A0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:89\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[39mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data]\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items)\n\u001b[0;32m     90\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:53\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m transform(\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m---> 53\u001b[0m \u001b[39mreturn\u001b[39;00m transform(parameters)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\spatial\\dictionary.py:662\u001b[0m, in \u001b[0;36mOrientationd.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    661\u001b[0m meta_data \u001b[39m=\u001b[39m d[meta_key]\n\u001b[1;32m--> 662\u001b[0m d[key], old_affine, new_affine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mornt_transform(d[key], affine\u001b[39m=\u001b[39;49mmeta_data[\u001b[39m\"\u001b[39;49m\u001b[39maffine\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    663\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_transform(d, key, extra_info\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmeta_key\u001b[39m\u001b[39m\"\u001b[39m: meta_key, \u001b[39m\"\u001b[39m\u001b[39mold_affine\u001b[39m\u001b[39m\"\u001b[39m: old_affine})\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\spatial\\array.py:557\u001b[0m, in \u001b[0;36mOrientation.__call__\u001b[1;34m(self, data_array, affine)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dst) \u001b[39m<\u001b[39m sr:\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maxcodes must match data_array spatially, got axcodes=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxcodes)\u001b[39m}\u001b[39;00m\u001b[39mD data_array=\u001b[39m\u001b[39m{\u001b[39;00msr\u001b[39m}\u001b[39;00m\u001b[39mD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m     )\n\u001b[0;32m    560\u001b[0m spatial_ornt \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39morientations\u001b[39m.\u001b[39mornt_transform(src, dst)\n",
      "\u001b[1;31mValueError\u001b[0m: axcodes must match data_array spatially, got axcodes=3D data_array=4D",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\steve\\OneDrive\\Documents\\IntroToDL\\MLfun\\Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\\alittletesting.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainloader \u001b[39m=\u001b[39m prepare(training_directory)\n",
      "\u001b[1;32mc:\\Users\\steve\\OneDrive\\Documents\\IntroToDL\\MLfun\\Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\\alittletesting.ipynb Cell 6\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(in_dir, pixdim, a_min, a_max, spatial_size, trainloader_batchsize)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m train_files \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m: image_name, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: label_name} \u001b[39mfor\u001b[39;00m image_name, label_name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(path_train_volumes, path_train_segmentation)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m train_transform \u001b[39m=\u001b[39m Compose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m         LoadImaged(keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m )\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m train_ds \u001b[39m=\u001b[39m CacheDataset(data\u001b[39m=\u001b[39;49mtrain_files, transform\u001b[39m=\u001b[39;49mtrain_transform,cache_rate\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_ds, batch_size\u001b[39m=\u001b[39mtrainloader_batchsize)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/steve/OneDrive/Documents/IntroToDL/MLfun/Segmentation%20Labels%20and%20Radiomic%20Features%20for%20the%20Pre-operative%20Scans%20of%20the%20TCGA-GBM%20collection/alittletesting.ipynb#W5sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPreparing done.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:723\u001b[0m, in \u001b[0;36mCacheDataset.__init__\u001b[1;34m(self, data, transform, cache_num, cache_rate, num_workers, progress, copy_cache, as_contiguous, hash_as_key, hash_func)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache: Union[List, Dict] \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 723\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_data(data)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:748\u001b[0m, in \u001b[0;36mCacheDataset.set_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n\u001b[1;32m--> 748\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m _compute_cache()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:737\u001b[0m, in \u001b[0;36mCacheDataset.set_data.<locals>._compute_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute_cache\u001b[39m():\n\u001b[0;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_num), \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_rate), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata))\n\u001b[1;32m--> 737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fill_cache()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:757\u001b[0m, in \u001b[0;36mCacheDataset._fill_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39mwith\u001b[39;00m ThreadPool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m    756\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress \u001b[39mand\u001b[39;00m has_tqdm:\n\u001b[1;32m--> 757\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    758\u001b[0m             tqdm(\n\u001b[0;32m    759\u001b[0m                 p\u001b[39m.\u001b[39;49mimap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_cache_item, \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_num)),\n\u001b[0;32m    760\u001b[0m                 total\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_num,\n\u001b[0;32m    761\u001b[0m                 desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLoading dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    762\u001b[0m             )\n\u001b[0;32m    763\u001b[0m         )\n\u001b[0;32m    764\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(p\u001b[39m.\u001b[39mimap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_cache_item, \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_num)))\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\multiprocessing\\pool.py:868\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 868\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[39m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m, func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m wrap_exception \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\data\\dataset.py:777\u001b[0m, in \u001b[0;36mCacheDataset._load_cache_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    776\u001b[0m     _xform \u001b[39m=\u001b[39m deepcopy(_transform) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[39melse\u001b[39;00m _transform\n\u001b[1;32m--> 777\u001b[0m     item \u001b[39m=\u001b[39m apply_transform(_xform, item)\n\u001b[0;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_contiguous:\n\u001b[0;32m    779\u001b[0m     item \u001b[39m=\u001b[39m convert_to_contiguous(item, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcontiguous_format)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\envs\\pytorchMain\\lib\\site-packages\\monai\\transforms\\transform.py:113\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         _log_stats(data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m--> 113\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplying transform \u001b[39m\u001b[39m{\u001b[39;00mtransform\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <monai.transforms.spatial.dictionary.Orientationd object at 0x00000238816729A0>"
     ]
    }
   ],
   "source": [
    "\n",
    "trainloader = prepare(training_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorchMain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea52dcf60439bbfeb15ff1bd40b703081e3cad41733c2dee57afaa83da4e6a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
